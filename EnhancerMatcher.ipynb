{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd123b76-2deb-4324-826a-cc66de199066",
   "metadata": {},
   "source": [
    "## The purpose of this notebook is to be the final version of EnhancerMatcher for publication\n",
    "\n",
    "### This notebook will take 2 input fasta files of 400 base pair length and output their probability of being a enhancer\n",
    "### Optional, output will also have a Class Activation map of the triplet sequences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "716841a7-c389-4145-9d78-ef8f9bf81ec6",
   "metadata": {},
   "source": [
    "### @author: Luis Solis, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "### @author: William Melendez, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "### @author: Sayantan Paul, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "### @author: Shantanu Hemantrao Fuke, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "### @author: Dr. Hani Z. Girgis, Bioinformatics Toolsmith Laboratory, Texas A&M University-Kingsville\n",
    "\n",
    "#### Date Created: 12-3-2024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b3de229-8d2c-4cc4-9ec9-0ae67b314640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "from Nets import CustomConvLayer\n",
    "from Metrics import specificity\n",
    "\n",
    "from Bio import SeqIO\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223c69a0-01d9-4da1-865d-b3fea87e93f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_cam_pdf = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e22c0ce-4704-4a5e-ac95-d6638ee307e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "Input 1 will include the two confirmed enhancers from the same cell type and must be in fasta format\n",
    "Input 2 will include all sequences that will be tested to see if they are similar to the first two sequences, this must also be in fasta format\n",
    "\n",
    "Output will include\n",
    "'''\n",
    "\n",
    "similar_sequences_file = f'Test_Input/input1.fasta'\n",
    "all_sequences_file     = f'Test_Input/input2.fasta'\n",
    "human_indexer          = f'indexer.pkl'\n",
    "\n",
    "triplet_model_file     = f'Models/conv_model.keras'\n",
    "class_model_file       = f'Models/class_model.keras'\n",
    "cam_model_file         = f'Models/cam_model.keras'\n",
    "\n",
    "output_dir             = f'Output'\n",
    "\n",
    "max_len = 400"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5363438-4908-4ba5-ae9a-1297df06a95b",
   "metadata": {},
   "source": [
    "### Load all models used for EnhancerTracker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6e36a25-2e45-4549-894a-eab22542d831",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = load_model(triplet_model_file, custom_objects={'CustomConvLayer': CustomConvLayer,'specificity': specificity})\n",
    "class_model = load_model(class_model_file, custom_objects={'CustomConvLayer': CustomConvLayer,'specificity': specificity})\n",
    "cam_model = load_model(cam_model_file, custom_objects={'CustomConvLayer': CustomConvLayer,'specificity': specificity})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4feebf-b321-44d5-988e-c37ec30666d9",
   "metadata": {},
   "source": [
    "### Load indexer used for encoding the sequences to numerical format the model understands "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a678ab1-682d-4a7f-b080-db4ca11467af",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(human_indexer, 'rb') as f:\n",
    "    indexer = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8183c92-16ad-4411-af9d-bfc71bbfe3bd",
   "metadata": {},
   "source": [
    "### Parse input files and grab their names for output and CAM\n",
    "### Encode the input sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07ebb1d6-c930-4642-b560-c85e96883341",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_seq_list = list(SeqIO.parse(similar_sequences_file, \"fasta\"))\n",
    "all_sequence_list = list(SeqIO.parse(all_sequences_file, \"fasta\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7e81af5-c604-4441-8463-e1147a36b5e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar_name_list = []\n",
    "all_name_list = []\n",
    "\n",
    "for seq in similar_seq_list:\n",
    "    similar_name_list.append(seq.id)\n",
    "\n",
    "for seq in all_sequence_list:\n",
    "    all_name_list.append(seq.id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11b703fa-adfe-4081-91d8-d8e04182accd",
   "metadata": {},
   "outputs": [],
   "source": [
    "matrix1  = indexer.encode_list(similar_seq_list)\n",
    "matrix2  = indexer.encode_list(all_sequence_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d148e5f4-cb0a-4dbb-8946-507b8a951860",
   "metadata": {},
   "source": [
    "### Create a zero tensor with shape of input for the model\n",
    "### Fill in the tensor with data from input files\n",
    "\n",
    "#### Tensor has 3 channels, 1st and 2nd channel are for input1 sequence 1 and 2. Channel 3 is for the sequence that will be identified from input2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03677aec-671a-487d-90de-27ddbf63b5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size   = matrix2.shape[0]\n",
    "row_size     = 1\n",
    "column_size  = matrix1.shape[1]\n",
    "channel_size = 3\n",
    "\n",
    "tensor  = np.zeros((batch_size, row_size, column_size, channel_size), dtype=np.int8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a875bb-2cd3-42db-a2b3-d11e4f90bb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ef2a10-b30e-4508-9d85-e50970b84766",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(batch_size):\n",
    "    tensor[i, :, :, 0] = matrix1[0]\n",
    "    tensor[i, :, :, 1] = matrix1[1]\n",
    "    tensor[i, :, :, 2] = matrix2[i]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b668a76b-c8f1-432c-8e94-ac4712af402b",
   "metadata": {},
   "source": [
    "### Predict the tensor and write results to output file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a432fe04-84a3-4f24-bbd9-b361da98ecfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_prediction = conv_model.predict(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58b652d9-37d0-4320-a69a-f1f7010c1023",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_output = [f\"{value[0]:.2f}\" for value in output_prediction]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe78dd73-33d3-4ac8-9685-cf3f557ed11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(f'{output_dir}/Model_Output.txt', 'w') as file:\n",
    "    for name, percentage in zip(all_name_list, formatted_output):\n",
    "        file.write(f\"{name} {percentage}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbb0dd85-1922-4728-8b3f-35311c7dff6e",
   "metadata": {},
   "source": [
    "### Below is code for making the CAM model\n",
    "### Cam model was based on code from Deep Learning with Python by Francois Chollet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c26d2ee-050e-4ce7-91db-76301bec324c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_CAM_map(heatmap_interpolated_list, output_dir, name_list, save_pdf):\n",
    "    \"\"\"\n",
    "    This function generates a series of 1D heatmaps (color-maps) based on the provided input data and visualizes them in a single figure.\n",
    "    The heatmaps are displayed in three rows, each representing a different channel.\n",
    "\n",
    "    Inputs:\n",
    "    - heatmap_interpolated_list (list): A list of 1D numpy arrays representing the heatmap data from the sequences. \n",
    "      Each array corresponds to a different channel to be visualized.\n",
    "    - output_dir (str): The directory path where the output figure will be saved.\n",
    "    - name_list (list): A list of strings representing the names or labels for each dataset. These will be used as titles \n",
    "      for the individual subplots.\n",
    "    - save_pdf (bool): A boolean indicating whether the figure should be saved as a PDF.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig, axs = plt.subplots(3, 1, figsize=(8.5, 5))  # 3 rows, 1 column\n",
    "    for i, heatmap_interpolated in enumerate(heatmap_interpolated_list):                  \n",
    "        image = axs[i].matshow(heatmap_interpolated.reshape(1, -1), cmap='jet', aspect='auto', vmin=0, vmax=1)\n",
    "        axs[i].set_yticks([])\n",
    "        axs[i].xaxis.set_ticks_position('bottom') \n",
    "        axs[i].set_xlim(-0.5, len(heatmap_interpolated))\n",
    "\n",
    "        axs[i].set_title(f'{name_list[i].split(\":\", 1)[1]}', fontsize=14)\n",
    "        \n",
    "        if i == 2:\n",
    "            axs[i].set_xlabel('Nucleotide position', fontsize=14)\n",
    "            axs[i].tick_params(axis='x', labelsize=14) \n",
    "        else:\n",
    "            axs[i].set_xticks([])\n",
    "\n",
    "        fig.colorbar(image, ax=axs[i])\n",
    "\n",
    "        # Remove the box around the heat map\n",
    "        axs[i].spines['top'].set_visible(False)\n",
    "        axs[i].spines['right'].set_visible(False)\n",
    "        axs[i].spines['left'].set_visible(False)\n",
    "        axs[i].spines['bottom'].set_visible(False)\n",
    "        \n",
    "    plt.tight_layout()\n",
    "\n",
    "    # Only save the figure if save_pdf is True\n",
    "    if save_pdf:\n",
    "        plt.savefig(f'{output_dir}.pdf')  # Save the plot as a PDF\n",
    "\n",
    "    plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6544f20b-9bd4-40be-b933-f08409e1041a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cam(x_batch_sample):\n",
    "    \"\"\"\n",
    "    This function computes Class Activation Maps (CAM) for a given batch of input samples.\n",
    "   \n",
    "    Inputs:\n",
    "    - x_batch_sample: The input batch of samples for which CAMs will be calculated.\n",
    "      It is passed through the `cam_model` to get the feature maps.\n",
    "\n",
    "    Outputs:\n",
    "    - heatmap_list (list): A list of heatmaps (numpy arrays), one for each feature map in the input batch. \n",
    "      Each heatmap corresponds to the importance of different regions of the input image with respect to the model's \n",
    "      predictions.\n",
    "    \"\"\"\n",
    "    \n",
    "    with tf.GradientTape(persistent=True) as tape:\n",
    "        # Get the CAM model output\n",
    "        cam_output_np = cam_model.predict(x_batch_sample, verbose=0)\n",
    "\n",
    "        # Convert each array in the list to a TensorFlow tensor and watch them\n",
    "        cam_output_tensors = [tf.convert_to_tensor(array, dtype=tf.float32) for array in cam_output_np]\n",
    "        for tensor in cam_output_tensors:\n",
    "            tape.watch(tensor)\n",
    "\n",
    "        # Use the tensors as inputs to the class_model\n",
    "        preds = class_model(cam_output_tensors)[0]\n",
    "    \n",
    "    # Calculate the gradients with respect to each of the cam_output_tensors\n",
    "    grads_list = [tape.gradient(preds, tensor) for tensor in cam_output_tensors]\n",
    "\n",
    "    # Dispose the tape manually since it's persistent\n",
    "    del tape\n",
    "\n",
    "    cam_output_arrays = [tensor.numpy() for tensor in cam_output_tensors]\n",
    "    heatmap_list = []\n",
    "    for j, grads in enumerate(grads_list):\n",
    "        pooled_grads = tf.reduce_mean(grads, axis=(0, 1, 2)).numpy()\n",
    "\n",
    "        last_conv_layer_output = cam_output_arrays[j]\n",
    "        \n",
    "        for i in range(pooled_grads.shape[-1]):\n",
    "            # last_conv_layer_output[:, :, :, i] *= (-1 * pooled_grads[i])\n",
    "            last_conv_layer_output[:, :, :, i] *= pooled_grads[i]\n",
    "\n",
    "        # Apply ReLU to the mean of the gradient-weighted features\n",
    "        # heatmap = np.mean(last_conv_layer_output, axis=-1)\n",
    "        \n",
    "        heatmap = np.max(last_conv_layer_output, axis=-1)\n",
    "        heatmap = np.maximum(heatmap, 0)      \n",
    "        heatmap_list.append(heatmap)\n",
    "\n",
    "    return heatmap_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bbc2cd7-dfa4-4e3d-9c0a-f8930c02b9f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_array(an_array):\n",
    "    '''\n",
    "    This code was generated by ChatGPT\n",
    "    '''\n",
    "    min_val    = np.min(an_array)\n",
    "    max_val    = np.max(an_array)\n",
    "    scaled_arr = (an_array - min_val) / ((max_val - min_val) + np.finfo(np.float64).eps)\n",
    "    \n",
    "    return scaled_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0756c913-7f19-4fd6-88e3-4da884945407",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sequence(triplet_index):\n",
    "    \"\"\"\n",
    "    Extract Sequence Name using IndexNow processing control: Enhancer\n",
    "    \"\"\"       \n",
    "    seq_name_list = []\n",
    "    seq_name_list.append(similar_name_list[0])\n",
    "    seq_name_list.append(similar_name_list[1])\n",
    "    seq_name_list.append(all_name_list[triplet_index])\n",
    " \n",
    "    return seq_name_list"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8df47d-9365-4ca3-92f9-32d5f1fe727b",
   "metadata": {},
   "source": [
    "### The CAM only gets generated if output_cam_pdf is True\n",
    "### The code will go through each sequence in input2 and calculate a cam and plot the heatmap\n",
    "### The heatmap will then get outputed to the output file as a pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bee15909-50f4-45bb-8d92-5af0a49261fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if output_cam_pdf:\n",
    "    for batch_idx in range(tensor.shape[0]):\n",
    "        batch = tensor[batch_idx]\n",
    "        batch = np.expand_dims(batch, axis=1)\n",
    "        \n",
    "        heatmap_list = calculate_cam(batch)\n",
    "    \n",
    "        heatmap_interpolated_list = []\n",
    "        for i, heatmap in enumerate(heatmap_list):\n",
    "            heatmap = scale_array(heatmap)\n",
    "            old_indices = np.linspace(0, heatmap.shape[2] - 1, num=heatmap.shape[2])\n",
    "            new_indices = np.linspace(0, heatmap.shape[2] - 1, num=max_len)\n",
    "            heatmap_interpolated = np.interp(new_indices, old_indices, heatmap[0, 0, :])\n",
    "            heatmap_interpolated_list.append(heatmap_interpolated)\n",
    "        name_list = get_sequence(batch_idx)\n",
    "        plot_CAM_map(heatmap_interpolated_list,f'{output_dir}/{name_list[2]}_CAM',name_list, True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-gpu",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
